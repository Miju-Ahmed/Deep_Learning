{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f765aea",
   "metadata": {},
   "source": [
    "Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100af247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 14:33:42.227532: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748075622.379968   11069 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748075622.423615   11069 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748075622.766846   11069 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748075622.766894   11069 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748075622.766934   11069 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748075622.766937   11069 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-24 14:33:42.796198: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.datasets.cifar100 import load_data\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50, InceptionV3, VGG16, EfficientNetB0, DenseNet121, Xception, NASNetMobile, InceptionResNetV2, EfficientNetV2B0\n",
    "from tensorflow.keras.models import Model;\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a306ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED =  50\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173e47e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43811704",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = random.sample(range(100), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b773de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_classes(x,y,selected):\n",
    "    x_filtered = []\n",
    "    y_filtered = []\n",
    "    class_map = {cls: idx for idx, cls in enumerate(selected)}\n",
    "    for img, label in zip(x,y):\n",
    "        if label[0] in selected:\n",
    "            x_filtered.append(img)\n",
    "            y_filtered.append(class_map[label[0]])\n",
    "    return np.array(x_filtered), np.array(y_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4644679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = filter_classes(x_train, y_train, classes)\n",
    "x_test, y_test = filter_classes(x_test, y_test, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4436ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x,y):\n",
    "    x = tf.image.resize(x,(224,224))/255.0\n",
    "    y = to_categorical(y, num_classes=20)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bbf7a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1748075649.510175   11069 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-05-24 14:34:09.560180: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6021120000 exceeds 10% of free system memory.\n",
      "2025-05-24 14:34:14.471137: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6021120000 exceeds 10% of free system memory.\n",
      "2025-05-24 14:34:17.213520: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1204224000 exceeds 10% of free system memory.\n",
      "2025-05-24 14:34:18.262372: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1204224000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = preprocess_data(x_train, y_train)\n",
    "x_test, y_test = preprocess_data(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3fee0a",
   "metadata": {},
   "source": [
    "1. MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26da3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "model_0.trainable = False # Freeze base layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "023dd90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model_0.input\n",
    "output = model_0.output\n",
    "x = GlobalAveragePooling2D()(output)\n",
    "outputs = Dense(20, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cee0828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 554ms/step - accuracy: 0.1589 - loss: 2.7636 - val_accuracy: 0.4815 - val_loss: 1.8746\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 567ms/step - accuracy: 0.5297 - loss: 1.6899 - val_accuracy: 0.6195 - val_loss: 1.3779\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 547ms/step - accuracy: 0.6502 - loss: 1.2743 - val_accuracy: 0.6655 - val_loss: 1.1616\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 541ms/step - accuracy: 0.6860 - loss: 1.0786 - val_accuracy: 0.6910 - val_loss: 1.0443\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 541ms/step - accuracy: 0.7096 - loss: 0.9651 - val_accuracy: 0.7070 - val_loss: 0.9701\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b703ce8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 431ms/step - accuracy: 0.7066 - loss: 0.9543\n",
      "Test Accuracy for MobileNetV2: 69.80%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy for MobileNetV2: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812b45e",
   "metadata": {},
   "source": [
    "ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34039ba3",
   "metadata": {},
   "source": [
    "2. Pretrained model ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce9a2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "model_resnet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "280cd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model_resnet.input\n",
    "outputs = model_resnet.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(outputs)\n",
    "outputs = Dense(20, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8e8beb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 2s/step - accuracy: 0.0494 - loss: 3.0520 - val_accuracy: 0.0525 - val_loss: 2.9954\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 2s/step - accuracy: 0.0559 - loss: 2.9940 - val_accuracy: 0.0550 - val_loss: 2.9915\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 2s/step - accuracy: 0.0588 - loss: 2.9897 - val_accuracy: 0.0555 - val_loss: 2.9877\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 2s/step - accuracy: 0.0630 - loss: 2.9855 - val_accuracy: 0.0565 - val_loss: 2.9840\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 2s/step - accuracy: 0.0677 - loss: 2.9814 - val_accuracy: 0.0560 - val_loss: 2.9803\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55fe1d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.0598 - loss: 2.9757\n",
      "Test Accuracy for ResNet50: 5.65%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy for ResNet50: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f23ae",
   "metadata": {},
   "source": [
    "3. VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d861afa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "model_vgg16.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56552b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model_vgg16.input\n",
    "outputs = model_vgg16.output\n",
    "x = GlobalAveragePooling2D()(outputs)\n",
    "outputs = Dense(20, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d80431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m972s\u001b[0m 4s/step - accuracy: 0.0509 - loss: 3.1013 - val_accuracy: 0.0470 - val_loss: 2.9597\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m960s\u001b[0m 4s/step - accuracy: 0.0882 - loss: 2.9465 - val_accuracy: 0.1675 - val_loss: 2.9100\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m962s\u001b[0m 4s/step - accuracy: 0.1821 - loss: 2.8975 - val_accuracy: 0.2035 - val_loss: 2.8709\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m951s\u001b[0m 4s/step - accuracy: 0.2223 - loss: 2.8573 - val_accuracy: 0.2290 - val_loss: 2.8337\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m919s\u001b[0m 4s/step - accuracy: 0.2398 - loss: 2.8196 - val_accuracy: 0.2480 - val_loss: 2.7986\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c328feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 3s/step - accuracy: 0.2476 - loss: 2.7937\n",
      "Test Accuracy for VGG16: 25.80%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy for VGG16: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d1f005",
   "metadata": {},
   "source": [
    "4. EfficientNetB0 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a954ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efficientnet = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "model_efficientnet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4848f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model_efficientnet.input\n",
    "outputs = model_efficientnet.output\n",
    "x = GlobalAveragePooling2D()(outputs)\n",
    "outputs = Dense(20, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04013b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 825ms/step - accuracy: 0.0489 - loss: 3.0101 - val_accuracy: 0.0525 - val_loss: 3.0005\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 822ms/step - accuracy: 0.0521 - loss: 3.0002 - val_accuracy: 0.0525 - val_loss: 3.0001\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 821ms/step - accuracy: 0.0548 - loss: 2.9999 - val_accuracy: 0.0525 - val_loss: 3.0005\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 872ms/step - accuracy: 0.0503 - loss: 2.9995 - val_accuracy: 0.0525 - val_loss: 3.0004\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 830ms/step - accuracy: 0.0491 - loss: 3.0002 - val_accuracy: 0.0525 - val_loss: 3.0001\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ef16adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 643ms/step - accuracy: 0.0528 - loss: 2.9970\n",
      "Test Accuracy for EfficientNetB0: 5.00%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy for EfficientNetB0: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a536a0a1",
   "metadata": {},
   "source": [
    "5. DenseNet121 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9741156",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_densenet = DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "model_densenet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba509b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model_densenet.input\n",
    "outputs = model_densenet.output\n",
    "x = GlobalAveragePooling2D()(outputs)\n",
    "outputs = Dense(20, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecf508b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 2s/step - accuracy: 0.0696 - loss: 3.2561 - val_accuracy: 0.2720 - val_loss: 2.4387\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 2s/step - accuracy: 0.3429 - loss: 2.3053 - val_accuracy: 0.4885 - val_loss: 1.8874\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 2s/step - accuracy: 0.5201 - loss: 1.8106 - val_accuracy: 0.5770 - val_loss: 1.5658\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 2s/step - accuracy: 0.6045 - loss: 1.5159 - val_accuracy: 0.6320 - val_loss: 1.3678\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 2s/step - accuracy: 0.6504 - loss: 1.3294 - val_accuracy: 0.6595 - val_loss: 1.2363\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c8f3cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - accuracy: 0.6493 - loss: 1.2759\n",
      "Test Accuracy for DenseNet121: 66.05%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy for DenseNet121: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a921a7",
   "metadata": {},
   "source": [
    "6. NASNetMobile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19b4e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nasnet = NASNetMobile(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "model_nasnet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4feefa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model_nasnet.input\n",
    "outputs = model_nasnet.output\n",
    "x = GlobalAveragePooling2D()(outputs)\n",
    "outputs = Dense(20, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3c5078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 651ms/step - accuracy: 0.1883 - loss: 2.7652 - val_accuracy: 0.5370 - val_loss: 1.9510\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 595ms/step - accuracy: 0.5900 - loss: 1.7513 - val_accuracy: 0.6660 - val_loss: 1.3989\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 594ms/step - accuracy: 0.6887 - loss: 1.2889 - val_accuracy: 0.7110 - val_loss: 1.1453\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 596ms/step - accuracy: 0.7213 - loss: 1.0684 - val_accuracy: 0.7270 - val_loss: 1.0111\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 597ms/step - accuracy: 0.7413 - loss: 0.9451 - val_accuracy: 0.7365 - val_loss: 0.9291\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da471375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 477ms/step - accuracy: 0.7293 - loss: 0.9526\n",
      "Test Accuracy for NASNetMobile: 72.85%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy for NASNetMobile: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9390dc9b",
   "metadata": {},
   "source": [
    "7. EfficientNetV2B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f6e6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efficientv2 = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "model_efficientv2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f7393cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model_efficientv2.input\n",
    "outputs = model_efficientv2.output\n",
    "x = GlobalAveragePooling2D()(outputs)\n",
    "outputs = Dense(20, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60ccadd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 586ms/step - accuracy: 0.0499 - loss: 3.0135 - val_accuracy: 0.0525 - val_loss: 3.0001\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 518ms/step - accuracy: 0.0528 - loss: 3.0014 - val_accuracy: 0.0525 - val_loss: 2.9998\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 524ms/step - accuracy: 0.0505 - loss: 3.0009 - val_accuracy: 0.0525 - val_loss: 2.9997\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 521ms/step - accuracy: 0.0496 - loss: 3.0002 - val_accuracy: 0.0525 - val_loss: 2.9994\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 517ms/step - accuracy: 0.0529 - loss: 3.0009 - val_accuracy: 0.0525 - val_loss: 2.9995\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef158793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 406ms/step - accuracy: 0.0528 - loss: 2.9967\n",
      "Test Accuracy for EfficientNetV2B0: 5.00%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy for EfficientNetV2B0: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b6337",
   "metadata": {},
   "source": [
    "8. InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf27a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "model_inception.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df34f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model_inception.input\n",
    "outputs = model_inception.output\n",
    "x = GlobalAveragePooling2D()(outputs)\n",
    "outputs = Dense(20, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecdb3f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 1s/step - accuracy: 0.6868 - loss: 1.2324 - val_accuracy: 0.7200 - val_loss: 1.0238\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 988ms/step - accuracy: 0.7456 - loss: 0.9297 - val_accuracy: 0.7480 - val_loss: 0.8917\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 824ms/step - accuracy: 0.7714 - loss: 0.8017 - val_accuracy: 0.7620 - val_loss: 0.8226\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 825ms/step - accuracy: 0.7849 - loss: 0.7240 - val_accuracy: 0.7680 - val_loss: 0.7792\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 827ms/step - accuracy: 0.7970 - loss: 0.6689 - val_accuracy: 0.7730 - val_loss: 0.7490\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02a2d7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 656ms/step - accuracy: 0.7564 - loss: 0.7832\n",
      "Test Accuracy for InceptionV3: 74.85%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy for InceptionV3: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc03187b",
   "metadata": {},
   "source": [
    "9. Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc6d508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception = Xception(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "model_xception.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8bd22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model_xception.input\n",
    "outputs = model_xception.output\n",
    "x = GlobalAveragePooling2D()(outputs)\n",
    "outputs = Dense(20, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3137938b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 2s/step - accuracy: 0.2372 - loss: 2.7119 - val_accuracy: 0.6605 - val_loss: 1.7473\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 2s/step - accuracy: 0.6956 - loss: 1.5786 - val_accuracy: 0.7340 - val_loss: 1.2221\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 2s/step - accuracy: 0.7439 - loss: 1.1474 - val_accuracy: 0.7550 - val_loss: 1.0054\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 2s/step - accuracy: 0.7632 - loss: 0.9570 - val_accuracy: 0.7660 - val_loss: 0.8934\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 2s/step - accuracy: 0.7771 - loss: 0.8510 - val_accuracy: 0.7720 - val_loss: 0.8251\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ea504f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.7744 - loss: 0.8275\n",
      "Test Accuracy for Xception: 76.70%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy for Xception: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86135273",
   "metadata": {},
   "source": [
    "10. InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2020c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inceptionv2 = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "model_inceptionv2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22372213",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model_inceptionv2.input\n",
    "outputs = model_inceptionv2.output\n",
    "x = GlobalAveragePooling2D()(outputs)\n",
    "outputs = Dense(20, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74342d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 2s/step - accuracy: 0.2712 - loss: 2.5983 - val_accuracy: 0.7035 - val_loss: 1.2580\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 2s/step - accuracy: 0.7224 - loss: 1.1417 - val_accuracy: 0.7565 - val_loss: 0.8808\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 2s/step - accuracy: 0.7731 - loss: 0.8368 - val_accuracy: 0.7780 - val_loss: 0.7523\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 2s/step - accuracy: 0.7937 - loss: 0.7158 - val_accuracy: 0.7885 - val_loss: 0.6858\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 2s/step - accuracy: 0.8091 - loss: 0.6466 - val_accuracy: 0.8005 - val_loss: 0.6439\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24951592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 1s/step - accuracy: 0.7894 - loss: 0.6656\n",
      "Test Accuracy for InceptionResNetV2: 79.30%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy for InceptionResNetV2: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b57e0b",
   "metadata": {},
   "source": [
    "Clear GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3edce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 13:58:14.228861: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748073494.246274   60202 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748073494.252261   60202 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748073494.265016   60202 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748073494.265032   60202 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748073494.265034   60202 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748073494.265035   60202 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-24 13:58:14.269096: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "import gc\n",
    "\n",
    "K.clear_session()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45e9532c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (29176056.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    source tf-env/bin/activate\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "source tf-env/bin/activate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
